{"cells":[{"cell_type":"markdown","metadata":{},"source":["# See Detailed code at https://github.com/aayush9753/ColorIt"]},{"cell_type":"code","execution_count":14,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2021-09-07T17:03:23.305733Z","iopub.status.idle":"2021-09-07T17:03:23.306388Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","metadata":{},"source":["## Importing Libraries"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2021-09-07T17:03:38.592211Z","iopub.status.busy":"2021-09-07T17:03:38.591857Z","iopub.status.idle":"2021-09-07T17:03:40.391267Z","shell.execute_reply":"2021-09-07T17:03:40.390386Z","shell.execute_reply.started":"2021-09-07T17:03:38.592180Z"},"trusted":true},"outputs":[],"source":["import glob\n","import random\n","import os\n","import numpy as np\n","\n","import torch\n","from torch.utils.data import Dataset\n","from PIL import Image\n","import torchvision.transforms as transforms\n","from torch import nn\n","from matplotlib import pyplot as plt\n","\n","#from pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM\n","\n","import argparse\n","import os\n","import numpy as np\n","import math\n","import itertools\n","import sys\n","\n","import torchvision.transforms as transforms\n","from torchvision.utils import save_image, make_grid\n","\n","from torch.utils.data import DataLoader\n","from torch.autograd import Variable\n","\n","#from models import *\n","#from datasets import *\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch\n","\n","\n","from torchvision.models import vgg19\n","\n","from skimage import color\n","from IPython import embed"]},{"cell_type":"markdown","metadata":{},"source":["## Util"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2021-09-07T17:03:43.411614Z","iopub.status.busy":"2021-09-07T17:03:43.411277Z","iopub.status.idle":"2021-09-07T17:03:43.424540Z","shell.execute_reply":"2021-09-07T17:03:43.423494Z","shell.execute_reply.started":"2021-09-07T17:03:43.411584Z"},"trusted":true},"outputs":[],"source":["def load_img(img_path):\n","\tout_np = np.asarray(Image.open(img_path))\n","\tif(out_np.ndim==2):\n","\t\tout_np = np.tile(out_np[:,:,None],3)\n","\treturn out_np\n","\n","def resize_img(img, HW=(256,256), resample=3):\n","\treturn np.asarray(Image.fromarray(img).resize((HW[1],HW[0]), resample=resample))\n","\n","def preprocess_img(img_rgb_orig, HW=(256,256), resample=3):\n","\t# return original size L and resized L as torch Tensors\n","\timg_rgb_rs = resize_img(img_rgb_orig, HW=HW, resample=resample)\n","\t\n","\timg_lab_orig = color.rgb2lab(img_rgb_orig)\n","\timg_lab_rs = color.rgb2lab(img_rgb_rs)\n","\n","\timg_l_orig = img_lab_orig[:,:,0]\n","\timg_l_rs = img_lab_rs[:,:,0]\n","\n","\ttens_orig_l = torch.Tensor(img_l_orig)[None,None,:,:]\n","\ttens_rs_l = torch.Tensor(img_l_rs)[None,None,:,:]\n","\n","\treturn (tens_orig_l, tens_rs_l)\n","\n","def postprocess_tens_new(tens_orig_l, out_ab, mode='bilinear'):\n","\t# tens_orig_l \tBatchsize x 1 x H_orig x W_orig\n","\t# out_ab \t\tBatchsize x 2 x H x W\n","    Batchsize = tens_orig_l.shape[0]\n","\n","    output_ = []\n","    for i in range(Batchsize):\n","        tens_orig_l_i = tens_orig_l[i][np.newaxis, :, :, :]\n","        out_ab_i  = out_ab[i][np.newaxis, :, :, :]\n","        HW_orig_i = tens_orig_l_i.shape[2:]\n","        HW_i = out_ab_i.shape[2:]\n","\n","        # call resize function if needed\n","        if(HW_orig_i[0]!=HW_i[0] or HW_orig_i[1]!=HW_i[1]):\n","            out_ab_orig_i = F.interpolate(out_ab_i, size=HW_orig_i, mode='bilinear')\n","        else:\n","            out_ab_orig_i = out_ab_i\n","\n","        out_lab_orig_i = torch.cat((tens_orig_l_i, out_ab_orig_i), dim=1)\n","        #output_.append(color.lab2rgb(out_lab_orig_i.data.cpu().numpy()[0,...].transpose((1,2,0))))\n","        output_.append(color.lab2rgb(out_lab_orig_i.data.cpu().numpy()[0,...].transpose((1,2,0))).transpose((2,0,1)))\n","    return np.array(output_)"]},{"cell_type":"markdown","metadata":{},"source":["# Models\n","## ECV16\n","This Model is based on the paper Colorful Image Colorization https://arxiv.org/abs/1603.08511 which we will train using a GAN with the ECV Model (A normal residual convnet model proposed in the paper) as the generator and a discriminator that we will design."]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2021-09-07T17:03:44.386173Z","iopub.status.busy":"2021-09-07T17:03:44.385798Z","iopub.status.idle":"2021-09-07T17:03:44.419085Z","shell.execute_reply":"2021-09-07T17:03:44.417690Z","shell.execute_reply.started":"2021-09-07T17:03:44.386139Z"},"trusted":true},"outputs":[],"source":["class BaseColor(nn.Module):\n","\tdef __init__(self):\n","\t\tsuper(BaseColor, self).__init__()\n","\n","\t\tself.l_cent = 50.\n","\t\tself.l_norm = 100.\n","\t\tself.ab_norm = 110.\n","\n","\tdef normalize_l(self, in_l):\n","\t\treturn (in_l-self.l_cent)/self.l_norm\n","\n","\tdef unnormalize_l(self, in_l):\n","\t\treturn in_l*self.l_norm + self.l_cent\n","\n","\tdef normalize_ab(self, in_ab):\n","\t\treturn in_ab/self.ab_norm\n","\n","\tdef unnormalize_ab(self, in_ab):\n","\t\treturn in_ab*self.ab_norm\n","\n","\n","class ECCVGenerator(BaseColor):\n","    def __init__(self, norm_layer=nn.BatchNorm2d):\n","        super(ECCVGenerator, self).__init__()\n","\n","        model1=[nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=True),]\n","        model1+=[nn.ReLU(True),]\n","        model1+=[nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1, bias=True),]\n","        model1+=[nn.ReLU(True),]\n","        model1+=[norm_layer(64),]\n","\n","        model2=[nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=True),]\n","        model2+=[nn.ReLU(True),]\n","        model2+=[nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1, bias=True),]\n","        model2+=[nn.ReLU(True),]\n","        model2+=[norm_layer(128),]\n","\n","        model3=[nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1, bias=True),]\n","        model3+=[nn.ReLU(True),]\n","        model3+=[nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True),]\n","        model3+=[nn.ReLU(True),]\n","        model3+=[nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1, bias=True),]\n","        model3+=[nn.ReLU(True),]\n","        model3+=[norm_layer(256),]\n","\n","        model4=[nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1, bias=True),]\n","        model4+=[nn.ReLU(True),]\n","        model4+=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]\n","        model4+=[nn.ReLU(True),]\n","        model4+=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]\n","        model4+=[nn.ReLU(True),]\n","        model4+=[norm_layer(512),]\n","\n","        model5=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]\n","        model5+=[nn.ReLU(True),]\n","        model5+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]\n","        model5+=[nn.ReLU(True),]\n","        model5+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]\n","        model5+=[nn.ReLU(True),]\n","        model5+=[norm_layer(512),]\n","\n","        model6=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]\n","        model6+=[nn.ReLU(True),]\n","        model6+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]\n","        model6+=[nn.ReLU(True),]\n","        model6+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]\n","        model6+=[nn.ReLU(True),]\n","        model6+=[norm_layer(512),]\n","\n","        model7=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]\n","        model7+=[nn.ReLU(True),]\n","        model7+=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]\n","        model7+=[nn.ReLU(True),]\n","        model7+=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]\n","        model7+=[nn.ReLU(True),]\n","        model7+=[norm_layer(512),]\n","\n","        model8=[nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=True),]\n","        model8+=[nn.ReLU(True),]\n","        model8+=[nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True),]\n","        model8+=[nn.ReLU(True),]\n","        model8+=[nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True),]\n","        model8+=[nn.ReLU(True),]\n","\n","        model8+=[nn.Conv2d(256, 313, kernel_size=1, stride=1, padding=0, bias=True),]\n","\n","        self.model1 = nn.Sequential(*model1)\n","        self.model2 = nn.Sequential(*model2)\n","        self.model3 = nn.Sequential(*model3)\n","        self.model4 = nn.Sequential(*model4)\n","        self.model5 = nn.Sequential(*model5)\n","        self.model6 = nn.Sequential(*model6)\n","        self.model7 = nn.Sequential(*model7)\n","        self.model8 = nn.Sequential(*model8)\n","\n","        self.softmax = nn.Softmax(dim=1)\n","        self.model_out = nn.Conv2d(313, 2, kernel_size=1, padding=0, dilation=1, stride=1, bias=False)\n","        self.upsample4 = nn.Upsample(scale_factor=4, mode='bilinear')\n","\n","    def forward(self, input_l):\n","        conv1_2 = self.model1(self.normalize_l(input_l))\n","        conv2_2 = self.model2(conv1_2)\n","        conv3_3 = self.model3(conv2_2)\n","        conv4_3 = self.model4(conv3_3)\n","        conv5_3 = self.model5(conv4_3)\n","        conv6_3 = self.model6(conv5_3)\n","        conv7_3 = self.model7(conv6_3)\n","        conv8_3 = self.model8(conv7_3)\n","        out_reg = self.model_out(self.softmax(conv8_3))\n","\n","        return self.unnormalize_ab(self.upsample4(out_reg))\n","\n","def eccv16(pretrained=True):\n","\tmodel = ECCVGenerator()\n","\tif(pretrained):\n","\t\timport torch.utils.model_zoo as model_zoo\n","\t\tmodel.load_state_dict(model_zoo.load_url('https://colorizers.s3.us-east-2.amazonaws.com/colorization_release_v2-9b330a0b.pth',map_location='cpu',check_hash=True))\n","\treturn model\n"]},{"cell_type":"markdown","metadata":{},"source":["## Feature Extractor\n","This is a noval approach to compare to images and use that comparison as a loss to train a model.\n","We will use a pre-trained VGG19 model. Two images are passed in it and the activations of the 18th layers are taken for both the images and then this activations are used to calculate the loss which can be calculated using RMSE, MSE etc between the two activations."]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2021-09-07T17:03:45.201201Z","iopub.status.busy":"2021-09-07T17:03:45.200852Z","iopub.status.idle":"2021-09-07T17:03:45.206855Z","shell.execute_reply":"2021-09-07T17:03:45.205670Z","shell.execute_reply.started":"2021-09-07T17:03:45.201171Z"},"trusted":true},"outputs":[],"source":["class FeatureExtractor(nn.Module):\n","    def __init__(self):\n","        super(FeatureExtractor, self).__init__()\n","        vgg19_model = vgg19(pretrained=True)\n","        self.feature_extractor = nn.Sequential(*list(vgg19_model.features.children())[:18])\n","\n","    def forward(self, img):\n","        return self.feature_extractor(img)"]},{"cell_type":"markdown","metadata":{},"source":["## Discriminator\n","Takes an image as input and converts it into a single no. after passing through several convolutional blocks."]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2021-09-07T17:03:46.483457Z","iopub.status.busy":"2021-09-07T17:03:46.483078Z","iopub.status.idle":"2021-09-07T17:03:46.493703Z","shell.execute_reply":"2021-09-07T17:03:46.492438Z","shell.execute_reply.started":"2021-09-07T17:03:46.483425Z"},"trusted":true},"outputs":[],"source":["class Discriminator(nn.Module):\n","    def __init__(self, input_shape):\n","        super(Discriminator, self).__init__()\n","\n","        self.input_shape = input_shape\n","        in_channels, in_height, in_width = self.input_shape\n","        patch_h, patch_w = int(in_height / 2 ** 4), int(in_width / 2 ** 4)\n","        self.output_shape = (1, patch_h, patch_w)\n","\n","        def discriminator_block(in_filters, out_filters, first_block=False):\n","            layers = []\n","            layers.append(nn.Conv2d(in_filters, out_filters, kernel_size=3, stride=1, padding=1))\n","            if not first_block:\n","                layers.append(nn.BatchNorm2d(out_filters))\n","            layers.append(nn.LeakyReLU(0.2, inplace=True))\n","            layers.append(nn.Conv2d(out_filters, out_filters, kernel_size=3, stride=2, padding=1))\n","            layers.append(nn.BatchNorm2d(out_filters))\n","            layers.append(nn.LeakyReLU(0.2, inplace=True))\n","            return layers\n","\n","        layers = []\n","        in_filters = in_channels\n","        for i, out_filters in enumerate([64, 128, 256, 512]):\n","            layers.extend(discriminator_block(in_filters, out_filters, first_block=(i == 0)))\n","            in_filters = out_filters\n","\n","        layers.append(nn.Conv2d(out_filters, 1, kernel_size=3, stride=1, padding=1))\n","\n","        self.model = nn.Sequential(*layers)\n","\n","    def forward(self, img):\n","        return self.model(img)"]},{"cell_type":"markdown","metadata":{},"source":["# Image Dataset"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2021-09-07T17:03:47.609596Z","iopub.status.busy":"2021-09-07T17:03:47.609268Z","iopub.status.idle":"2021-09-07T17:03:47.773896Z","shell.execute_reply":"2021-09-07T17:03:47.773145Z","shell.execute_reply.started":"2021-09-07T17:03:47.609565Z"},"trusted":true},"outputs":[{"ename":"ValueError","evalue":"num_samples should be a positive integer value, but got num_samples=0","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32m/Users/harrymacbook/Documents/VisualCodes/ICE_MP/gan_state_to_Full.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 42>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/harrymacbook/Documents/VisualCodes/ICE_MP/gan_state_to_Full.ipynb#X16sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m root \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../input/image-colorization-dataset/data/train_black/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/harrymacbook/Documents/VisualCodes/ICE_MP/gan_state_to_Full.ipynb#X16sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m transform \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/harrymacbook/Documents/VisualCodes/ICE_MP/gan_state_to_Full.ipynb#X16sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m             [\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/harrymacbook/Documents/VisualCodes/ICE_MP/gan_state_to_Full.ipynb#X16sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m                 \u001b[39m#transforms.Resize((shape[0], shape[1]), Image.BICUBIC),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/harrymacbook/Documents/VisualCodes/ICE_MP/gan_state_to_Full.ipynb#X16sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m             ]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/harrymacbook/Documents/VisualCodes/ICE_MP/gan_state_to_Full.ipynb#X16sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m         )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/harrymacbook/Documents/VisualCodes/ICE_MP/gan_state_to_Full.ipynb#X16sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m dataloader \u001b[39m=\u001b[39m DataLoader(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/harrymacbook/Documents/VisualCodes/ICE_MP/gan_state_to_Full.ipynb#X16sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     ImageDataset(root, transform),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/harrymacbook/Documents/VisualCodes/ICE_MP/gan_state_to_Full.ipynb#X16sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/harrymacbook/Documents/VisualCodes/ICE_MP/gan_state_to_Full.ipynb#X16sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/harrymacbook/Documents/VisualCodes/ICE_MP/gan_state_to_Full.ipynb#X16sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     num_workers\u001b[39m=\u001b[39mn_cpu,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/harrymacbook/Documents/VisualCodes/ICE_MP/gan_state_to_Full.ipynb#X16sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m )\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py:277\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# map-style\u001b[39;00m\n\u001b[1;32m    276\u001b[0m     \u001b[39mif\u001b[39;00m shuffle:\n\u001b[0;32m--> 277\u001b[0m         sampler \u001b[39m=\u001b[39m RandomSampler(dataset, generator\u001b[39m=\u001b[39;49mgenerator)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    278\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m         sampler \u001b[39m=\u001b[39m SequentialSampler(dataset)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/utils/data/sampler.py:97\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mreplacement should be a boolean value, but got \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mreplacement=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplacement))\n\u001b[1;32m     96\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples, \u001b[39mint\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 97\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mnum_samples should be a positive integer \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mvalue, but got num_samples=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples))\n","\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"]}],"source":["batch_size = 4\n","n_cpu = 0\n","out_channels = 3\n","\n","class ImageDataset(Dataset):\n","    def __init__(self, root, transform): #, shape):\n","        #height, width = shape\n","        self.transform = transform\n","\n","        self.files = sorted(glob.glob(root + \"/*.*\"))\n","\n","    def __getitem__(self, index):\n","        \n","        black_path = self.files[index % len(self.files)]\n","        color_path = black_path.replace('black','color')\n","        \n","        img_black = np.asarray(Image.open(black_path))\n","        if(img_black.ndim==2):\n","            img_black = np.tile(img_black[:,:,None],3)\n","        (tens_l_orig, tens_l_rs) = preprocess_img(img_black, HW=(400, 400))\n","        #img_bw = postprocess_tens(tens_l_orig, torch.cat((0*tens_l_orig,0*tens_l_orig),dim=1))\n","        #img_black = self.transform(img_black)\n","        \n","        \n","        img_color = Image.open(color_path)\n","        img_color = self.transform(img_color)\n","\n","        return {\"black\": tens_l_rs.squeeze(0), 'orig': tens_l_orig.squeeze(0), \"color\": img_color}\n","\n","\n","    def __len__(self):\n","        return len(self.files)\n","\n","root = '../input/image-colorization-dataset/data/train_black/'\n","transform = transforms.Compose(\n","            [\n","                #transforms.Resize((shape[0], shape[1]), Image.BICUBIC),\n","                transforms.ToTensor(),\n","                #transforms.Normalize(mean, std),\n","            ]\n","        )\n","dataloader = DataLoader(\n","    ImageDataset(root, transform),\n","    batch_size=batch_size,\n","    shuffle=True,\n","    num_workers=n_cpu,\n",")"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2021-09-07T17:03:48.301021Z","iopub.status.busy":"2021-09-07T17:03:48.300736Z","iopub.status.idle":"2021-09-07T17:03:49.480479Z","shell.execute_reply":"2021-09-07T17:03:49.479303Z","shell.execute_reply.started":"2021-09-07T17:03:48.300991Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'dataloader' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m/Users/harrymacbook/Documents/VisualCodes/ICE_MP/gan_state_to_Full.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/harrymacbook/Documents/VisualCodes/ICE_MP/gan_state_to_Full.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dataiter \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(dataloader)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/harrymacbook/Documents/VisualCodes/ICE_MP/gan_state_to_Full.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m data \u001b[39m=\u001b[39m dataiter\u001b[39m.\u001b[39mnext()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/harrymacbook/Documents/VisualCodes/ICE_MP/gan_state_to_Full.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n","\u001b[0;31mNameError\u001b[0m: name 'dataloader' is not defined"]}],"source":["dataiter = iter(dataloader)\n","data = dataiter.next()\n","\n","i = 1\n","img = data['black'][i].permute(1, 2, 0)\n","print(img.shape)\n","t = np.zeros((400, 400, 3))\n","t[..., 0] = img[..., 0]\n","t = color.lab2rgb(t)\n","plt.imshow(t)\n","plt.show()\n","\n","img = data['orig'][i].permute(1, 2, 0)\n","print(img.shape)\n","t = np.zeros((400, 400, 3))\n","t[..., 0] = img[..., 0]\n","t = color.lab2rgb(t)\n","plt.imshow(t)\n","plt.show()\n","\n","print(img.shape)\n","img = data['color'][i].permute(1, 2, 0)\n","plt.imshow(img)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Initialising Models and Training Params"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2021-09-07T17:03:49.482215Z","iopub.status.busy":"2021-09-07T17:03:49.481867Z","iopub.status.idle":"2021-09-07T17:03:49.487687Z","shell.execute_reply":"2021-09-07T17:03:49.486485Z","shell.execute_reply.started":"2021-09-07T17:03:49.482175Z"},"trusted":true},"outputs":[],"source":["class color_ecv(nn.Module):\n","    def __init__(self, in_channels):\n","        super(color_ecv, self).__init__()\n","        \n","        self.model = eccv16(pretrained=True)\n","    \n","    def forward(self, x):\n","        ecv_output = self.model(x)\n","        return ecv_output"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2021-09-07T17:03:50.099622Z","iopub.status.busy":"2021-09-07T17:03:50.099154Z","iopub.status.idle":"2021-09-07T17:03:50.104425Z","shell.execute_reply":"2021-09-07T17:03:50.103598Z","shell.execute_reply.started":"2021-09-07T17:03:50.099579Z"},"trusted":true},"outputs":[],"source":["os.makedirs(\"colorit_gan/images\", exist_ok=True)\n","os.makedirs(\"colorit_gan/saved_models\", exist_ok=True)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2021-09-07T17:03:51.121362Z","iopub.status.busy":"2021-09-07T17:03:51.121021Z","iopub.status.idle":"2021-09-07T17:03:51.203164Z","shell.execute_reply":"2021-09-07T17:03:51.202216Z","shell.execute_reply.started":"2021-09-07T17:03:51.121333Z"},"trusted":true},"outputs":[],"source":["start_epoch = 0\n","n_epochs= 50\n","\n","lr = 0.0002\n","b1 = 0.5\n","b2 = 0.999\n","decay_epoch = 100\n","in_channels = 1\n","out_channels = 3\n","sample_interval = 100\n","checkpoint_interval = 1\n","\n"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2021-09-07T17:03:52.249397Z","iopub.status.busy":"2021-09-07T17:03:52.249064Z","iopub.status.idle":"2021-09-07T17:04:08.144201Z","shell.execute_reply":"2021-09-07T17:04:08.143338Z","shell.execute_reply.started":"2021-09-07T17:03:52.249364Z"},"trusted":true},"outputs":[],"source":["shape = (400, 400)\n","cuda = torch.cuda.is_available()\n","# Initialize generator and discriminator\n","generator = color_ecv(in_channels = 3)\n","discriminator = Discriminator(input_shape=(out_channels, *shape))\n","feature_extractor = FeatureExtractor()\n","\n","# Set feature extractor to inference mode\n","feature_extractor.eval()\n","\n","# Losses\n","criterion_GAN = torch.nn.MSELoss()\n","criterion_content = torch.nn.L1Loss()\n","\n","if cuda:\n","    generator = generator.cuda()\n","    discriminator = discriminator.cuda()\n","    feature_extractor = feature_extractor.cuda()\n","    criterion_GAN = criterion_GAN.cuda()\n","    criterion_content = criterion_content.cuda()"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2021-09-07T17:04:08.147706Z","iopub.status.busy":"2021-09-07T17:04:08.147437Z","iopub.status.idle":"2021-09-07T17:04:08.153982Z","shell.execute_reply":"2021-09-07T17:04:08.153190Z","shell.execute_reply.started":"2021-09-07T17:04:08.147679Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# if start_epoch != 0:\n","    # Load pretrained models\n","generator.load_state_dict(torch.load(\"generator_59.pth\" , map_location=torch.device('cpu')))\n","    # discriminator.load_state_dict(torch.load(\"colorit_gan/saved_models/discriminator_\"+str(start_epoch-1)+\".pth\"))\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["torch.save(generator, \"generator_Full.pth\")"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["color_ecv(\n","  (model): ECCVGenerator(\n","    (model1): Sequential(\n","      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model2): Sequential(\n","      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model3): Sequential(\n","      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (5): ReLU(inplace=True)\n","      (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model4): Sequential(\n","      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (5): ReLU(inplace=True)\n","      (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model5): Sequential(\n","      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","      (3): ReLU(inplace=True)\n","      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","      (5): ReLU(inplace=True)\n","      (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model6): Sequential(\n","      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","      (3): ReLU(inplace=True)\n","      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","      (5): ReLU(inplace=True)\n","      (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model7): Sequential(\n","      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (5): ReLU(inplace=True)\n","      (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model8): Sequential(\n","      (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (5): ReLU(inplace=True)\n","      (6): Conv2d(256, 313, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (softmax): Softmax(dim=1)\n","    (model_out): Conv2d(313, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (upsample4): Upsample(scale_factor=4.0, mode=bilinear)\n","  )\n",")"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["model = torch.load(\"generator_Full.pth\")\n","model.eval()"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"data":{"text/plain":["color_ecv(\n","  (model): ECCVGenerator(\n","    (model1): Sequential(\n","      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model2): Sequential(\n","      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model3): Sequential(\n","      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (5): ReLU(inplace=True)\n","      (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model4): Sequential(\n","      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (5): ReLU(inplace=True)\n","      (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model5): Sequential(\n","      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","      (3): ReLU(inplace=True)\n","      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","      (5): ReLU(inplace=True)\n","      (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model6): Sequential(\n","      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","      (3): ReLU(inplace=True)\n","      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","      (5): ReLU(inplace=True)\n","      (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model7): Sequential(\n","      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (5): ReLU(inplace=True)\n","      (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model8): Sequential(\n","      (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (5): ReLU(inplace=True)\n","      (6): Conv2d(256, 313, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (softmax): Softmax(dim=1)\n","    (model_out): Conv2d(313, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (upsample4): Upsample(scale_factor=4.0, mode=bilinear)\n","  )\n",")"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["generator.load_state_dict(torch.load(\"generator.pth\" , map_location=torch.device('cpu')))\n","torch.save(generator, \"generator_Full.pth\")\n","model = torch.load(\"generator_Full.pth\")\n","model.eval()"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/plain":["color_ecv(\n","  (model): ECCVGenerator(\n","    (model1): Sequential(\n","      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model2): Sequential(\n","      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model3): Sequential(\n","      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (5): ReLU(inplace=True)\n","      (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model4): Sequential(\n","      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (5): ReLU(inplace=True)\n","      (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model5): Sequential(\n","      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","      (3): ReLU(inplace=True)\n","      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","      (5): ReLU(inplace=True)\n","      (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model6): Sequential(\n","      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","      (3): ReLU(inplace=True)\n","      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","      (5): ReLU(inplace=True)\n","      (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model7): Sequential(\n","      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (5): ReLU(inplace=True)\n","      (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model8): Sequential(\n","      (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (5): ReLU(inplace=True)\n","      (6): Conv2d(256, 313, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (softmax): Softmax(dim=1)\n","    (model_out): Conv2d(313, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (upsample4): Upsample(scale_factor=4.0, mode=bilinear)\n","  )\n",")"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["generator.load_state_dict(torch.load(\"generator_59.pth\" , map_location=torch.device('cpu')))\n","torch.save(generator, \"generator_59_Full.pth\")\n","model = torch.load(\"generator_59_Full.pth\")\n","model.eval()"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["color_ecv(\n","  (model): ECCVGenerator(\n","    (model1): Sequential(\n","      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model2): Sequential(\n","      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model3): Sequential(\n","      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (5): ReLU(inplace=True)\n","      (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model4): Sequential(\n","      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (5): ReLU(inplace=True)\n","      (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model5): Sequential(\n","      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","      (3): ReLU(inplace=True)\n","      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","      (5): ReLU(inplace=True)\n","      (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model6): Sequential(\n","      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","      (3): ReLU(inplace=True)\n","      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","      (5): ReLU(inplace=True)\n","      (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model7): Sequential(\n","      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (5): ReLU(inplace=True)\n","      (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model8): Sequential(\n","      (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (5): ReLU(inplace=True)\n","      (6): Conv2d(256, 313, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (softmax): Softmax(dim=1)\n","    (model_out): Conv2d(313, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (upsample4): Upsample(scale_factor=4.0, mode=bilinear)\n","  )\n",")"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["generator.load_state_dict(torch.load(\"generator_74.pth\" , map_location=torch.device('cpu')))\n","torch.save(generator, \"generator_74_Full.pth\")\n","model = torch.load(\"generator_74_Full.pth\")\n","model.eval()"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/plain":["color_ecv(\n","  (model): ECCVGenerator(\n","    (model1): Sequential(\n","      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model2): Sequential(\n","      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model3): Sequential(\n","      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (5): ReLU(inplace=True)\n","      (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model4): Sequential(\n","      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (5): ReLU(inplace=True)\n","      (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model5): Sequential(\n","      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","      (3): ReLU(inplace=True)\n","      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","      (5): ReLU(inplace=True)\n","      (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model6): Sequential(\n","      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","      (3): ReLU(inplace=True)\n","      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","      (5): ReLU(inplace=True)\n","      (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model7): Sequential(\n","      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (5): ReLU(inplace=True)\n","      (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model8): Sequential(\n","      (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (5): ReLU(inplace=True)\n","      (6): Conv2d(256, 313, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (softmax): Softmax(dim=1)\n","    (model_out): Conv2d(313, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (upsample4): Upsample(scale_factor=4.0, mode=bilinear)\n","  )\n",")"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["generator.load_state_dict(torch.load(\"generator_89.pth\" , map_location=torch.device('cpu')))\n","torch.save(generator, \"generator_89_Full.pth\")\n","model = torch.load(\"generator_89_Full.pth\")\n","model.eval()"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"data":{"text/plain":["color_ecv(\n","  (model): ECCVGenerator(\n","    (model1): Sequential(\n","      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model2): Sequential(\n","      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model3): Sequential(\n","      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (5): ReLU(inplace=True)\n","      (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model4): Sequential(\n","      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (5): ReLU(inplace=True)\n","      (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model5): Sequential(\n","      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","      (3): ReLU(inplace=True)\n","      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","      (5): ReLU(inplace=True)\n","      (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model6): Sequential(\n","      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","      (3): ReLU(inplace=True)\n","      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","      (5): ReLU(inplace=True)\n","      (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model7): Sequential(\n","      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (5): ReLU(inplace=True)\n","      (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (model8): Sequential(\n","      (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (5): ReLU(inplace=True)\n","      (6): Conv2d(256, 313, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (softmax): Softmax(dim=1)\n","    (model_out): Conv2d(313, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (upsample4): Upsample(scale_factor=4.0, mode=bilinear)\n","  )\n",")"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["generator.load_state_dict(torch.load(\"generator_89.pth\" , map_location=torch.device('cpu')))\n","torch.save(generator, \"generator_89_Full.pth\")\n","model = torch.load(\"generator_89_Full.pth\")\n","model.eval()"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision.transforms.functional as F\n","from PIL import Image\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","model = torch.load('generator_59_Full.pth')\n","model.eval()\n","model.to(device)\n","\n","transform = transforms.Compose([\n","    transforms.Resize((400, 400)),\n","    transforms.ToTensor()\n","    # transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","])\n","\n","input_image = Image.open('data/test_black/image5005.jpg').convert('L')\n","\n","# Resize and normalize the input image\n","input_image = F.resize(input_image, (400, 400))\n","input_tensor = F.to_tensor(input_image)\n","# input_tensor = F.normalize(input_tensor, [0.5], [0.5])\n","\n","# Add an extra dimension to the input tensor to create a batch of size 1\n","input_tensor = input_tensor.unsqueeze(0)\n","\n","# Run the model and get the output tensor\n","with torch.no_grad():\n","    output_tensor = model(input_tensor)\n","    output_tensor = output_tensor.squeeze().cpu().detach().numpy()\n","    output_tensor = output_tensor.transpose((1, 2, 0)) * 0.5 + 0.5\n","    output_tensor = (output_tensor * 255).astype('uint8')\n","    output_tensor = Image.fromarray(output_tensor)\n","\n","output_tensor = output_tensor.convert('RGB')\n","output_tensor.save('output4.jpg')\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.8"},"vscode":{"interpreter":{"hash":"8f0063560737609a141aa87b39577853acdfc9932e5c5196f0acdb90df11be1d"}}},"nbformat":4,"nbformat_minor":4}
